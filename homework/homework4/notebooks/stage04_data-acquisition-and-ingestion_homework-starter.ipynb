{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Starter — Stage 04: Data Acquisition and Ingestion\n",
    "Name: Mihir Subramaniam\n",
    "\n",
    "\n",
    "## Objectives\n",
    "- API ingestion with secrets in `.env`\n",
    "- Scrape a permitted public table\n",
    "- Validate and save raw data to `data/raw/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHAVANTAGE_API_KEY loaded? True\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib, datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "RAW = pathlib.Path('/Users/murli/Desktop/bootcamp_mihir_subramaniam/homework/homework4/data/raw'); RAW.mkdir(parents=True, exist_ok=True)\n",
    "load_dotenv(); print('ALPHAVANTAGE_API_KEY loaded?', bool(os.getenv('ALPHAVANTAGE_API_KEY')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers (use or modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts():\n",
    "    return dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "def save_csv(df: pd.DataFrame, prefix: str, **meta):\n",
    "    mid = '_'.join([f\"{k}-{v}\" for k,v in meta.items()])\n",
    "    path = RAW / f\"{prefix}_{mid}_{ts()}.csv\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print('Saved', path)\n",
    "    return path\n",
    "\n",
    "def validate(df: pd.DataFrame, required):\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    return {'missing': missing, 'shape': df.shape, 'na_total': int(df.isna().sum().sum())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 — API Pull (Required)\n",
    "Choose an endpoint (e.g., Alpha Vantage or use `yfinance` fallback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05239a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (0.2.65)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (2.2.6)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (2.32.4)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (4.3.8)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (3.18.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (4.13.4)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (6.32.0)\n",
      "Requirement already satisfied: websockets>=13.0 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from curl_cffi>=0.7->yfinance) (2025.8.3)\n",
      "Requirement already satisfied: pycparser in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/murli/anaconda3/envs/bootcamp_env/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'missing': [], 'shape': (100, 2), 'na_total': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYMBOL = 'MSFT'\n",
    "USE_ALPHA = bool(os.getenv('ALPHAVANTAGE_API_KEY'))\n",
    "if USE_ALPHA:\n",
    "    url = 'https://www.alphavantage.co/query'\n",
    "    params = {'function':'TIME_SERIES_DAILY','symbol':SYMBOL,'outputsize':'compact','apikey':os.getenv('ALPHAVANTAGE_API_KEY')}\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    js = r.json()\n",
    "    key = [k for k in js if 'Time Series' in k][0]\n",
    "    df_api = pd.DataFrame(js[key]).T.reset_index().rename(columns={'index':'date','4. close':'adj_close'})[['date','adj_close']]\n",
    "    df_api['date'] = pd.to_datetime(df_api['date']); df_api['adj_close'] = pd.to_numeric(df_api['adj_close'])\n",
    "else:\n",
    "    import yfinance as yf\n",
    "    df_api = yf.download(SYMBOL, period='3mo', interval='1d').reset_index()[['Date','Adj Close']]\n",
    "    df_api.columns = ['date','adj_close']\n",
    "\n",
    "v_api = validate(df_api, ['date','adj_close']); v_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /Users/murli/Desktop/bootcamp_mihir_subramaniam/homework/homework4/data/raw/api_source-alpha_symbol-MSFT_20250821-165047.csv\n"
     ]
    }
   ],
   "source": [
    "_ = save_csv(df_api.sort_values('date'), prefix='api', source='alpha' if USE_ALPHA else 'yfinance', symbol=SYMBOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 — Scrape a Public Table (Required)\n",
    "Replace `SCRAPE_URL` with a permitted page containing a simple table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /Users/murli/Desktop/bootcamp_mihir_subramaniam/homework/homework4/data/raw/scrape_site-wikipedia_table-countries_population_20250821-165726.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "SCRAPE_URL = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\"\n",
    "headers = {\"User-Agent\": \"AFE-Homework/1.0\", \"Accept-Language\": \"en-US,en;q=0.9\"}\n",
    "\n",
    "def _clean_numeric_string(s: str) -> str:\n",
    "    return (\n",
    "        str(s)\n",
    "        .replace(\"\\u00a0\", \" \")\n",
    "        .replace(\",\", \"\")\n",
    "        .replace(\"%\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "def _infer_and_coerce_numeric(df_in: pd.DataFrame, min_numeric_share: float = 0.8) -> pd.DataFrame:\n",
    "    df = df_in.copy()\n",
    "    for col in df.columns:\n",
    "        cleaned = (\n",
    "            df[col]\n",
    "            .astype(str)\n",
    "            .str.replace(r\"\\[[^\\]]*\\]\", \"\", regex=True)\n",
    "            .map(_clean_numeric_string)\n",
    "        )\n",
    "        as_num = pd.to_numeric(cleaned, errors=\"coerce\")\n",
    "        non_null = cleaned.notna().sum()\n",
    "        numeric_like = as_num.notna().sum()\n",
    "        \n",
    "        if non_null > 0 and numeric_like / non_null >= min_numeric_share:\n",
    "            df[col] = as_num\n",
    "        else:\n",
    "            \n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "                .str.strip()\n",
    "            )\n",
    "    return df\n",
    "\n",
    "try:\n",
    "    resp = requests.get(SCRAPE_URL, headers=headers, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "   \n",
    "    table = soup.select_one(\"table.wikitable\")\n",
    "    if table is None:\n",
    "        raise RuntimeError(\"No 'wikitable' found on the page.\")\n",
    "\n",
    "    \n",
    "    first_tr = table.find(\"tr\")\n",
    "    header_cells = first_tr.find_all([\"th\", \"td\"])\n",
    "    header = [re.sub(r\"\\s+\", \" \", th.get_text(strip=True)).replace(\"\\u00a0\", \" \") for th in header_cells]\n",
    "\n",
    "    \n",
    "    data = []\n",
    "    for tr in table.find_all(\"tr\")[1:]:\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if not tds:\n",
    "            continue\n",
    "        row = [re.sub(r\"\\s+\", \" \", td.get_text(strip=True)).replace(\"\\u00a0\", \" \") for td in tds]\n",
    "        if len(row) == len(header):\n",
    "            data.append(row)\n",
    "\n",
    "    if not data:\n",
    "        raise RuntimeError(\"No data rows parsed. Table schema may have changed.\")\n",
    "\n",
    "    df_scrape = pd.DataFrame(data, columns=header)\n",
    "\n",
    "    df_scrape = _infer_and_coerce_numeric(df_scrape, min_numeric_share=0.8)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Scrape failed, using inline demo table:\", e)\n",
    "    html = '<table><tr><th>Country</th><th>Population</th></tr><tr><td>Demo</td><td>1,234,567</td></tr></table>'\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    rows = [[c.get_text(strip=True) for c in tr.find_all([\"th\", \"td\"])] for tr in soup.find_all(\"tr\")]\n",
    "    header, *data = [r for r in rows if r]\n",
    "    df_scrape = pd.DataFrame(data, columns=header)\n",
    "    if \"Population\" in df_scrape.columns:\n",
    "        df_scrape[\"Population\"] = pd.to_numeric(df_scrape[\"Population\"].str.replace(\",\", \"\"), errors=\"coerce\")\n",
    "\n",
    "v_scrape = validate(df_scrape, list(df_scrape.columns)); v_scrape\n",
    "_ = save_csv(df_scrape, prefix=\"scrape\", site=\"wikipedia\", table=\"countries_population\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = save_csv(df_scrape, prefix='scrape', site='example', table='markets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "# API Source:\n",
    "\n",
    "- source: [alphavantage] https://www.alphavantage.co/query \n",
    "- Parameters:  \n",
    "  - function=TIME_SERIES_DAILY  \n",
    "  - symbol=MSFT \n",
    "  - outputsize=compact \n",
    "- Fallback: yfinance library (3-month daily adjusted close data for MSFT)  \n",
    "\n",
    "# Scrape Source:\n",
    "-  [Wikipedia, List of countries and dependencies by population] https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population \n",
    "- Table Description: first wikitable containing country names, population estimates, and related metadata.  \n",
    "- Parsing: using BeautifulSoup, cleaned headers, stripped whitespace and footnotes.  \n",
    "- Validation: numeric vs. text columns inferred by heuristic (≥80% numeric → coerced to numeric).\n",
    "\n",
    "\n",
    "# Assumptions & Risks\n",
    "\n",
    "- API:\n",
    "  - rate limits on Alpha Vantage (5 requests/min, 500/day).  \n",
    "  - api key must remain private (.env file not committed).  \n",
    "- Scrape:\n",
    "  - wikipedia tables may change format (header names, footnotes, new columns).  \n",
    "  - parsing assumes consistent structure of the first wikitable.  \n",
    "\n",
    "# Data storage\n",
    "- all processed files saved to data/raw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bootcamp_env]",
   "language": "python",
   "name": "bootcamp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
